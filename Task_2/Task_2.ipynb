{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df0005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25521077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470c5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22fd5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e46915",
   "metadata": {},
   "source": [
    "28x28 pictures of 10 classes (different clothes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "874f0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try model from lectures\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c11ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=.01)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40165c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "            \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aad3738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 8.084, train_loss: 1.754834234968145, train_acc: 0.5725166666666667, test_loss: 1.291440835595131, test_acc: 0.6502\n",
      "ep: 1, taked: 7.928, train_loss: 1.0745303942802105, train_acc: 0.6714333333333333, test_loss: 0.9443286776542663, test_acc: 0.6743\n",
      "ep: 2, taked: 7.989, train_loss: 0.8627835332079137, train_acc: 0.7076166666666667, test_loss: 0.816928681731224, test_acc: 0.708\n",
      "ep: 3, taked: 7.897, train_loss: 0.76775493241371, train_acc: 0.7397666666666667, test_loss: 0.7457274824380875, test_acc: 0.7373\n",
      "ep: 4, taked: 7.972, train_loss: 0.7086682091368005, train_acc: 0.76165, test_loss: 0.6970842495560646, test_acc: 0.7562\n",
      "ep: 5, taked: 7.952, train_loss: 0.666164341632356, train_acc: 0.7779166666666667, test_loss: 0.6608622029423714, test_acc: 0.7701\n",
      "ep: 6, taked: 8.051, train_loss: 0.6335285250176774, train_acc: 0.79085, test_loss: 0.6328013941645623, test_acc: 0.7816\n",
      "ep: 7, taked: 7.975, train_loss: 0.6076983564711632, train_acc: 0.7993166666666667, test_loss: 0.6105827130377293, test_acc: 0.7882\n",
      "ep: 8, taked: 7.947, train_loss: 0.5868068981677927, train_acc: 0.8054833333333333, test_loss: 0.592599855363369, test_acc: 0.7946\n",
      "ep: 9, taked: 7.921, train_loss: 0.5695822723368381, train_acc: 0.8106333333333333, test_loss: 0.5777696460485459, test_acc: 0.8004\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608ca71",
   "metadata": {},
   "source": [
    "Almost 83% accurace on test data. Try to change optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "185df23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 8.175, train_loss: 0.5712232366521308, train_acc: 0.8137333333333333, test_loss: 0.4376200843602419, test_acc: 0.8384\n",
      "ep: 1, taked: 8.060, train_loss: 0.3842448311917325, train_acc: 0.8609666666666667, test_loss: 0.3988906152546406, test_acc: 0.851\n",
      "ep: 2, taked: 8.113, train_loss: 0.35555202244444095, train_acc: 0.8701166666666666, test_loss: 0.40124424286186694, test_acc: 0.8569\n",
      "ep: 3, taked: 8.370, train_loss: 0.33095480989902576, train_acc: 0.8779666666666667, test_loss: 0.4114883128553629, test_acc: 0.8544\n",
      "ep: 4, taked: 8.376, train_loss: 0.317461353033147, train_acc: 0.8815833333333334, test_loss: 0.3884324960410595, test_acc: 0.8608\n",
      "ep: 5, taked: 8.571, train_loss: 0.3015201912281361, train_acc: 0.8883, test_loss: 0.3828570205718279, test_acc: 0.867\n",
      "ep: 6, taked: 8.545, train_loss: 0.29367436506646744, train_acc: 0.8906, test_loss: 0.4017509136348963, test_acc: 0.8568\n",
      "ep: 7, taked: 8.320, train_loss: 0.28823804037368045, train_acc: 0.8916, test_loss: 0.3925721973180771, test_acc: 0.8639\n",
      "ep: 8, taked: 8.400, train_loss: 0.2808989994703455, train_acc: 0.89585, test_loss: 0.4213628865778446, test_acc: 0.8629\n",
      "ep: 9, taked: 8.424, train_loss: 0.2743946273910238, train_acc: 0.8976333333333333, test_loss: 0.4376524519175291, test_acc: 0.8585\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c2dec",
   "metadata": {},
   "source": [
    "85,8% accuracy on test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff2ea4",
   "metadata": {},
   "source": [
    "Try to add more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35070e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 364),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(364, 182),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(182, 91),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(91, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c2d679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 8.906, train_loss: 0.582941064809231, train_acc: 0.78225, test_loss: 0.45518190041184425, test_acc: 0.8354\n",
      "ep: 1, taked: 8.903, train_loss: 0.3937876731791395, train_acc: 0.85595, test_loss: 0.384173284471035, test_acc: 0.8592\n",
      "ep: 2, taked: 8.923, train_loss: 0.3556922612038064, train_acc: 0.8694833333333334, test_loss: 0.4013810705393553, test_acc: 0.854\n",
      "ep: 3, taked: 9.533, train_loss: 0.33724620938301086, train_acc: 0.8757666666666667, test_loss: 0.4084973271936178, test_acc: 0.8552\n",
      "ep: 4, taked: 9.397, train_loss: 0.3242379588649628, train_acc: 0.8819333333333333, test_loss: 0.39130606278777125, test_acc: 0.8648\n",
      "ep: 5, taked: 9.467, train_loss: 0.31285658117304455, train_acc: 0.8842, test_loss: 0.3879812713712454, test_acc: 0.8603\n",
      "ep: 6, taked: 9.378, train_loss: 0.3024929778372988, train_acc: 0.8885333333333333, test_loss: 0.4067094687372446, test_acc: 0.8677\n",
      "ep: 7, taked: 9.528, train_loss: 0.29484824906004237, train_acc: 0.8909833333333333, test_loss: 0.3727956537157297, test_acc: 0.869\n",
      "ep: 8, taked: 9.698, train_loss: 0.28313083369681175, train_acc: 0.8952166666666667, test_loss: 0.38711047172546387, test_acc: 0.8689\n",
      "ep: 9, taked: 9.626, train_loss: 0.2862693000981148, train_acc: 0.8957833333333334, test_loss: 0.3727719519287348, test_acc: 0.8684\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512ca0e",
   "metadata": {},
   "source": [
    "86.84% accuracy , but loss doesn't show straight decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283227a5",
   "metadata": {},
   "source": [
    "try to add batch normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f7714a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 364),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(364, 182),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(182),\n",
    "    torch.nn.Linear(182, 91),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(91),\n",
    "    torch.nn.Linear(91, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "132cbd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 9.318, train_loss: 0.6207899536224122, train_acc: 0.7653333333333333, test_loss: 0.45960916578769684, test_acc: 0.827\n",
      "ep: 1, taked: 9.144, train_loss: 0.48432707469514075, train_acc: 0.8203666666666667, test_loss: 0.4262346997857094, test_acc: 0.8417\n",
      "ep: 2, taked: 9.135, train_loss: 0.4543297919821232, train_acc: 0.8323, test_loss: 0.4045132864266634, test_acc: 0.8511\n",
      "ep: 3, taked: 9.288, train_loss: 0.4248376984545525, train_acc: 0.8437666666666667, test_loss: 0.38359526693820956, test_acc: 0.8589\n",
      "ep: 4, taked: 9.400, train_loss: 0.4017868848557168, train_acc: 0.8510666666666666, test_loss: 0.37340935617685317, test_acc: 0.8635\n",
      "ep: 5, taked: 9.375, train_loss: 0.39611430028651623, train_acc: 0.8534666666666667, test_loss: 0.37155316546559336, test_acc: 0.8631\n",
      "ep: 6, taked: 9.339, train_loss: 0.3847947426298831, train_acc: 0.8581, test_loss: 0.3612911760807037, test_acc: 0.8669\n",
      "ep: 7, taked: 9.415, train_loss: 0.3738649185667647, train_acc: 0.8613333333333333, test_loss: 0.35762960873544214, test_acc: 0.8682\n",
      "ep: 8, taked: 9.317, train_loss: 0.3636738047954884, train_acc: 0.8649166666666667, test_loss: 0.36388908289372923, test_acc: 0.865\n",
      "ep: 9, taked: 9.351, train_loss: 0.35788610444424, train_acc: 0.8677, test_loss: 0.3518642261624336, test_acc: 0.8672\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2b93c",
   "metadata": {},
   "source": [
    "86.72% accuracy on test but loss behavior is better than without dropout and batch normalization\n",
    "Let's see after 100 epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eee33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 9.320, train_loss: 0.35080253393092053, train_acc: 0.86925, test_loss: 0.3383964210748672, test_acc: 0.8739\n",
      "ep: 1, taked: 9.337, train_loss: 0.34324849051363926, train_acc: 0.8733, test_loss: 0.33974580876529215, test_acc: 0.873\n",
      "ep: 2, taked: 9.616, train_loss: 0.3389359824834986, train_acc: 0.8729666666666667, test_loss: 0.3342988796532154, test_acc: 0.8751\n",
      "ep: 3, taked: 11.480, train_loss: 0.335876279688896, train_acc: 0.8754333333333333, test_loss: 0.3351643092930317, test_acc: 0.8749\n",
      "ep: 4, taked: 10.919, train_loss: 0.330397041363919, train_acc: 0.8767666666666667, test_loss: 0.3309714004397392, test_acc: 0.8779\n",
      "ep: 5, taked: 10.387, train_loss: 0.326869568989632, train_acc: 0.87725, test_loss: 0.33683025985956194, test_acc: 0.8771\n",
      "ep: 6, taked: 10.551, train_loss: 0.3251229147327707, train_acc: 0.8785666666666667, test_loss: 0.3274841759353876, test_acc: 0.8801\n",
      "ep: 7, taked: 10.108, train_loss: 0.31736624760830656, train_acc: 0.8807, test_loss: 0.3305462682619691, test_acc: 0.8774\n",
      "ep: 8, taked: 10.086, train_loss: 0.3169036039012544, train_acc: 0.8820333333333333, test_loss: 0.3353582456707954, test_acc: 0.8744\n",
      "ep: 9, taked: 10.099, train_loss: 0.3100392903419251, train_acc: 0.8853833333333333, test_loss: 0.33317869417369367, test_acc: 0.878\n",
      "ep: 10, taked: 10.335, train_loss: 0.3083641983727191, train_acc: 0.8860833333333333, test_loss: 0.328756158426404, test_acc: 0.8808\n",
      "ep: 11, taked: 10.112, train_loss: 0.30355922643174515, train_acc: 0.8866666666666667, test_loss: 0.33316650725901126, test_acc: 0.8755\n",
      "ep: 12, taked: 10.206, train_loss: 0.29999559388515795, train_acc: 0.8887833333333334, test_loss: 0.32558554466813805, test_acc: 0.8808\n",
      "ep: 13, taked: 10.121, train_loss: 0.3013456938114572, train_acc: 0.88705, test_loss: 0.322248076274991, test_acc: 0.8836\n",
      "ep: 14, taked: 10.267, train_loss: 0.2958548864785661, train_acc: 0.8902333333333333, test_loss: 0.3186534775421023, test_acc: 0.882\n",
      "ep: 15, taked: 10.177, train_loss: 0.29343733445126957, train_acc: 0.8887, test_loss: 0.3167799012735486, test_acc: 0.8862\n",
      "ep: 16, taked: 10.211, train_loss: 0.2899963059957991, train_acc: 0.8921333333333333, test_loss: 0.3220310429111123, test_acc: 0.8812\n",
      "ep: 17, taked: 10.200, train_loss: 0.2871280088703683, train_acc: 0.8916166666666666, test_loss: 0.3186009144410491, test_acc: 0.8846\n",
      "ep: 18, taked: 10.172, train_loss: 0.28672793456848633, train_acc: 0.8921166666666667, test_loss: 0.3155039379373193, test_acc: 0.8836\n",
      "ep: 19, taked: 10.119, train_loss: 0.2876568526029587, train_acc: 0.8916833333333334, test_loss: 0.31356733907014134, test_acc: 0.8839\n",
      "ep: 20, taked: 10.201, train_loss: 0.2815617624115437, train_acc: 0.89415, test_loss: 0.31002520173788073, test_acc: 0.8896\n",
      "ep: 21, taked: 10.131, train_loss: 0.2806577577869943, train_acc: 0.89645, test_loss: 0.3133121654391289, test_acc: 0.8872\n",
      "ep: 22, taked: 10.369, train_loss: 0.2790689471554249, train_acc: 0.8967166666666667, test_loss: 0.3112848397344351, test_acc: 0.8862\n",
      "ep: 23, taked: 10.250, train_loss: 0.27556082194155834, train_acc: 0.8966833333333334, test_loss: 0.3198282356373966, test_acc: 0.8832\n",
      "ep: 24, taked: 10.259, train_loss: 0.2754512916854087, train_acc: 0.8960666666666667, test_loss: 0.3132411819882691, test_acc: 0.8847\n",
      "ep: 25, taked: 10.285, train_loss: 0.27094857305922404, train_acc: 0.8983833333333333, test_loss: 0.3074100846424699, test_acc: 0.8887\n",
      "ep: 26, taked: 10.314, train_loss: 0.2697166419409691, train_acc: 0.8993666666666666, test_loss: 0.3046566266566515, test_acc: 0.8895\n",
      "ep: 27, taked: 10.222, train_loss: 0.26733120654491666, train_acc: 0.9003333333333333, test_loss: 0.3024785354733467, test_acc: 0.892\n",
      "ep: 28, taked: 10.242, train_loss: 0.2641971367470762, train_acc: 0.90015, test_loss: 0.3113844940438867, test_acc: 0.8872\n",
      "ep: 29, taked: 10.168, train_loss: 0.2624483229632073, train_acc: 0.901, test_loss: 0.30651410687714814, test_acc: 0.8865\n",
      "ep: 30, taked: 10.312, train_loss: 0.2644885926804644, train_acc: 0.9002833333333333, test_loss: 0.3148393101990223, test_acc: 0.8911\n",
      "ep: 31, taked: 10.248, train_loss: 0.2610819438670544, train_acc: 0.9022, test_loss: 0.304278139770031, test_acc: 0.8903\n",
      "ep: 32, taked: 10.315, train_loss: 0.2584414083272853, train_acc: 0.9028, test_loss: 0.30808239728212355, test_acc: 0.8908\n",
      "ep: 33, taked: 10.315, train_loss: 0.25564417021071656, train_acc: 0.90395, test_loss: 0.3052704883739352, test_acc: 0.8909\n",
      "ep: 34, taked: 10.316, train_loss: 0.2586747617163557, train_acc: 0.9025666666666666, test_loss: 0.2996944855898619, test_acc: 0.8916\n",
      "ep: 35, taked: 10.700, train_loss: 0.25363465167106464, train_acc: 0.9052166666666667, test_loss: 0.3077406357973814, test_acc: 0.8909\n",
      "ep: 36, taked: 10.685, train_loss: 0.25184217989444735, train_acc: 0.9053833333333333, test_loss: 0.3056474596261978, test_acc: 0.8904\n",
      "ep: 37, taked: 10.777, train_loss: 0.25382100882682396, train_acc: 0.9047, test_loss: 0.3051480920985341, test_acc: 0.8908\n",
      "ep: 38, taked: 11.226, train_loss: 0.24925220754552393, train_acc: 0.9078666666666667, test_loss: 0.30545529052615167, test_acc: 0.8901\n",
      "ep: 39, taked: 11.039, train_loss: 0.251207316746103, train_acc: 0.9068833333333334, test_loss: 0.3017727121710777, test_acc: 0.8925\n",
      "ep: 40, taked: 10.454, train_loss: 0.24596267729363544, train_acc: 0.9070166666666667, test_loss: 0.3047342419624329, test_acc: 0.8929\n",
      "ep: 41, taked: 10.246, train_loss: 0.2441844584459954, train_acc: 0.9077166666666666, test_loss: 0.30230835676193235, test_acc: 0.8923\n",
      "ep: 42, taked: 10.371, train_loss: 0.24284394351725883, train_acc: 0.9091, test_loss: 0.2989744769409299, test_acc: 0.8924\n",
      "ep: 43, taked: 10.400, train_loss: 0.24439926737166465, train_acc: 0.9086, test_loss: 0.2967400224879384, test_acc: 0.8947\n",
      "ep: 44, taked: 10.258, train_loss: 0.2423965330453629, train_acc: 0.9093666666666667, test_loss: 0.30813720598816874, test_acc: 0.8927\n",
      "ep: 45, taked: 10.328, train_loss: 0.2425959976429635, train_acc: 0.9076833333333333, test_loss: 0.29940206930041313, test_acc: 0.8899\n",
      "ep: 46, taked: 10.622, train_loss: 0.23986854451767942, train_acc: 0.90965, test_loss: 0.2992033313959837, test_acc: 0.8943\n",
      "ep: 47, taked: 10.308, train_loss: 0.23396571982414163, train_acc: 0.9110833333333334, test_loss: 0.30484764371067286, test_acc: 0.8898\n",
      "ep: 48, taked: 10.357, train_loss: 0.2352804923311193, train_acc: 0.9116833333333333, test_loss: 0.3016834992915392, test_acc: 0.8924\n",
      "ep: 49, taked: 10.735, train_loss: 0.23352821076169927, train_acc: 0.9125666666666666, test_loss: 0.302085617929697, test_acc: 0.893\n",
      "ep: 50, taked: 10.418, train_loss: 0.23535109241592123, train_acc: 0.9111166666666667, test_loss: 0.29946248438209294, test_acc: 0.8941\n",
      "ep: 51, taked: 10.391, train_loss: 0.23146049012529088, train_acc: 0.9119, test_loss: 0.31263233087956904, test_acc: 0.8892\n",
      "ep: 52, taked: 10.441, train_loss: 0.23283482035423847, train_acc: 0.9118333333333334, test_loss: 0.29793383497744796, test_acc: 0.893\n",
      "ep: 53, taked: 10.360, train_loss: 0.23003829083544142, train_acc: 0.9139166666666667, test_loss: 0.3060694357380271, test_acc: 0.8932\n",
      "ep: 54, taked: 10.354, train_loss: 0.22882154799522236, train_acc: 0.91345, test_loss: 0.3007286126725376, test_acc: 0.8944\n",
      "ep: 55, taked: 10.363, train_loss: 0.22628267026962118, train_acc: 0.91505, test_loss: 0.30380598455667496, test_acc: 0.8916\n",
      "ep: 56, taked: 10.339, train_loss: 0.22813915077676164, train_acc: 0.9142833333333333, test_loss: 0.3024588007479906, test_acc: 0.8939\n",
      "ep: 57, taked: 10.340, train_loss: 0.22562705887124893, train_acc: 0.9141166666666667, test_loss: 0.30094909723848107, test_acc: 0.8918\n",
      "ep: 58, taked: 10.304, train_loss: 0.22572746004195923, train_acc: 0.9145, test_loss: 0.314103390276432, test_acc: 0.8897\n",
      "ep: 59, taked: 10.300, train_loss: 0.22234919337516135, train_acc: 0.9162333333333333, test_loss: 0.2975302655249834, test_acc: 0.8969\n",
      "ep: 60, taked: 10.804, train_loss: 0.22177377026131811, train_acc: 0.9169666666666667, test_loss: 0.3031679896637797, test_acc: 0.8943\n",
      "ep: 61, taked: 10.467, train_loss: 0.22365201477040636, train_acc: 0.9158833333333334, test_loss: 0.3086267333477736, test_acc: 0.8952\n",
      "ep: 62, taked: 10.512, train_loss: 0.22100430023162923, train_acc: 0.9173333333333333, test_loss: 0.29736718758940694, test_acc: 0.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 63, taked: 10.457, train_loss: 0.21580635848197532, train_acc: 0.9194166666666667, test_loss: 0.30410245843231676, test_acc: 0.8953\n",
      "ep: 64, taked: 10.288, train_loss: 0.22025048948348835, train_acc: 0.9177333333333333, test_loss: 0.3021005308255553, test_acc: 0.8952\n",
      "ep: 65, taked: 10.457, train_loss: 0.2176143745792673, train_acc: 0.9183666666666667, test_loss: 0.30519613875076174, test_acc: 0.891\n",
      "ep: 66, taked: 10.492, train_loss: 0.21611709220612302, train_acc: 0.91895, test_loss: 0.3054430536925793, test_acc: 0.8949\n",
      "ep: 67, taked: 10.334, train_loss: 0.2142263578290635, train_acc: 0.9196333333333333, test_loss: 0.3001707514747977, test_acc: 0.8965\n",
      "ep: 68, taked: 10.441, train_loss: 0.21302467267564001, train_acc: 0.9208166666666666, test_loss: 0.29294221885502336, test_acc: 0.8963\n",
      "ep: 69, taked: 10.491, train_loss: 0.21106703395539142, train_acc: 0.9205, test_loss: 0.30397809874266385, test_acc: 0.8936\n",
      "ep: 70, taked: 10.360, train_loss: 0.21337299201082677, train_acc: 0.9197666666666666, test_loss: 0.30417683683335783, test_acc: 0.8958\n",
      "ep: 71, taked: 11.003, train_loss: 0.20900097904687231, train_acc: 0.9208166666666666, test_loss: 0.30209558829665184, test_acc: 0.896\n",
      "ep: 72, taked: 11.237, train_loss: 0.21281507281546896, train_acc: 0.9198333333333333, test_loss: 0.3035141944885254, test_acc: 0.8949\n",
      "ep: 73, taked: 10.650, train_loss: 0.20988140074496572, train_acc: 0.91995, test_loss: 0.30095622688531876, test_acc: 0.8968\n",
      "ep: 74, taked: 10.495, train_loss: 0.20849242115274388, train_acc: 0.9209333333333334, test_loss: 0.3072938047349453, test_acc: 0.894\n",
      "ep: 75, taked: 10.480, train_loss: 0.20945428574972966, train_acc: 0.9211333333333334, test_loss: 0.3040089450776577, test_acc: 0.8948\n",
      "ep: 76, taked: 10.371, train_loss: 0.2084185080642396, train_acc: 0.9217833333333333, test_loss: 0.3024511868134141, test_acc: 0.8959\n",
      "ep: 77, taked: 10.491, train_loss: 0.20538694024720092, train_acc: 0.9223166666666667, test_loss: 0.3093006182461977, test_acc: 0.8931\n",
      "ep: 78, taked: 10.473, train_loss: 0.2049397940014271, train_acc: 0.9227, test_loss: 0.3077246528118849, test_acc: 0.8942\n",
      "ep: 79, taked: 10.438, train_loss: 0.20596404861896597, train_acc: 0.9228333333333333, test_loss: 0.2994515776634216, test_acc: 0.8956\n",
      "ep: 80, taked: 10.457, train_loss: 0.20518470669680453, train_acc: 0.9220833333333334, test_loss: 0.3009250726550817, test_acc: 0.8965\n",
      "ep: 81, taked: 10.491, train_loss: 0.19928175290214253, train_acc: 0.92525, test_loss: 0.30480807423591616, test_acc: 0.8963\n",
      "ep: 82, taked: 10.373, train_loss: 0.207310680601191, train_acc: 0.92095, test_loss: 0.3052186926826835, test_acc: 0.896\n",
      "ep: 83, taked: 10.451, train_loss: 0.20141258927735878, train_acc: 0.9242333333333334, test_loss: 0.3126520778983831, test_acc: 0.8968\n",
      "ep: 84, taked: 10.870, train_loss: 0.20144845405791667, train_acc: 0.9244, test_loss: 0.3110116824507713, test_acc: 0.8979\n",
      "ep: 85, taked: 10.596, train_loss: 0.19987013901167727, train_acc: 0.9246666666666666, test_loss: 0.30574515126645563, test_acc: 0.8956\n",
      "ep: 86, taked: 10.591, train_loss: 0.20016553287810468, train_acc: 0.92425, test_loss: 0.3104576949030161, test_acc: 0.8974\n",
      "ep: 87, taked: 10.465, train_loss: 0.19954261763932857, train_acc: 0.9240833333333334, test_loss: 0.30366109367460015, test_acc: 0.8975\n",
      "ep: 88, taked: 10.332, train_loss: 0.19892964356757226, train_acc: 0.9251333333333334, test_loss: 0.3093626290559769, test_acc: 0.8949\n",
      "ep: 89, taked: 10.433, train_loss: 0.1972979851859681, train_acc: 0.9267, test_loss: 0.30647808574140073, test_acc: 0.8968\n",
      "ep: 90, taked: 10.386, train_loss: 0.19593932406699405, train_acc: 0.9260166666666667, test_loss: 0.30924943275749683, test_acc: 0.8953\n",
      "ep: 91, taked: 10.519, train_loss: 0.19461239810953748, train_acc: 0.92595, test_loss: 0.3089560206979513, test_acc: 0.8986\n",
      "ep: 92, taked: 10.406, train_loss: 0.19477014709660348, train_acc: 0.9261333333333334, test_loss: 0.3062375675886869, test_acc: 0.8948\n",
      "ep: 93, taked: 10.312, train_loss: 0.19305024695523243, train_acc: 0.9271833333333334, test_loss: 0.309742271900177, test_acc: 0.8986\n",
      "ep: 94, taked: 10.510, train_loss: 0.19310698043158714, train_acc: 0.9266166666666666, test_loss: 0.30695043168962, test_acc: 0.8968\n",
      "ep: 95, taked: 10.487, train_loss: 0.1947155682647482, train_acc: 0.9263666666666667, test_loss: 0.3123352289199829, test_acc: 0.8978\n",
      "ep: 96, taked: 11.069, train_loss: 0.1934784378460113, train_acc: 0.9268666666666666, test_loss: 0.3096672460436821, test_acc: 0.8984\n",
      "ep: 97, taked: 10.790, train_loss: 0.19220719800350514, train_acc: 0.9277333333333333, test_loss: 0.31052668765187263, test_acc: 0.8955\n",
      "ep: 98, taked: 10.691, train_loss: 0.19029440036479464, train_acc: 0.9275333333333333, test_loss: 0.3067976951599121, test_acc: 0.8978\n",
      "ep: 99, taked: 10.617, train_loss: 0.18809983321326845, train_acc: 0.9292666666666667, test_loss: 0.31162350010126827, test_acc: 0.8949\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e8460",
   "metadata": {},
   "source": [
    "test accuracy  89.49%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe65e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
